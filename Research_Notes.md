## Reasearch
* Web Crawling refers to downloading and storing the contents of a large number of websites


# Achievements
* Being able to gather all the links in a website
* Use deque and stack to gather the links recursively, more like a DFS approach
* Write the output to a file
* Setup Unit tests
* Added threading to some parts of the application

# Aim
* Look at the things I need to work on


# Things I need to work on
* Make sure the threading and optimization are efficient
* Write actual unit tests
* Rename variable to more suitable name
